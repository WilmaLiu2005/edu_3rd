"""
å‘½ä»¤è¡Œæ¥å£æ¨¡å—

æä¾›QAå¯¹è¯èšç±»åˆ†æçš„å®Œæ•´å·¥ä½œæµï¼ŒåŒ…æ‹¬ï¼š
- ç‰¹å¾æå–
- PCAé™ç»´åˆ†æ
- èšç±»åˆ†æ
- ç»“æœå¯è§†åŒ–
"""

import os
import sys
import json
from typing import Optional, Tuple, List
import pandas as pd

from .config import setup_plotting
from .features import extract_all_features
from .pca_utils import perform_pca_analysis
from .clustering import (
    find_optimal_clusters_elbow_only,
    perform_clustering,
    analyze_cluster_characteristics,
    comprehensive_clustering_visualization_all_k,
    plot_cluster_feature_heatmap
)
from .feature_utils import debug_infinite_values

# å¸¸é‡å®šä¹‰
DEFAULT_MAX_K = 10
DEFAULT_VARIANCE_THRESHOLD = 0.8
PREFERRED_FILE_EXTENSIONS = ('.csv', '.txt')
DEFAULT_CLUSTER_COLUMNS = ['cluster', 'cluster_k2', 'cluster_k3', 'cluster_k4']


def find_file_recursively(
    root_dir: str,
    file_name: str,
    prefer_exts: Tuple[str, ...] = PREFERRED_FILE_EXTENSIONS,
    case_insensitive: bool = True
) -> Optional[str]:
    """
    åœ¨æŒ‡å®šç›®å½•ä¸‹é€’å½’æŸ¥æ‰¾æ–‡ä»¶
    
    Args:
        root_dir: æ ¹ç›®å½•è·¯å¾„
        file_name: è¦æŸ¥æ‰¾çš„æ–‡ä»¶åï¼ˆå¯å¸¦æˆ–ä¸å¸¦åç¼€ï¼‰
        prefer_exts: ä¼˜å…ˆåŒ¹é…çš„æ–‡ä»¶æ‰©å±•åé¡ºåº
        case_insensitive: æ˜¯å¦å¤§å°å†™ä¸æ•æ„Ÿ
    
    Returns:
        str: æ‰¾åˆ°çš„æ–‡ä»¶å®Œæ•´è·¯å¾„ï¼Œæœªæ‰¾åˆ°è¿”å›None
    """
    if not file_name or not isinstance(file_name, str):
        return None

    # æ£€æŸ¥æ˜¯å¦ä¸ºç»å¯¹è·¯å¾„æˆ–å·²å­˜åœ¨çš„ç›¸å¯¹è·¯å¾„
    if os.path.isabs(file_name) and os.path.exists(file_name):
        return file_name
    
    direct_path = os.path.join(root_dir, file_name)
    if os.path.exists(direct_path):
        return direct_path

    # åˆ†ç¦»æ–‡ä»¶åå’Œæ‰©å±•å
    target = os.path.basename(file_name)
    tbase, text = os.path.splitext(target)
    tname_cmp = target.lower() if case_insensitive else target
    tbase_cmp = tbase.lower() if case_insensitive else tbase

    best_path = None
    best_rank = float('inf')

    # é€’å½’æœç´¢
    for root, _, files in os.walk(root_dir):
        for f in files:
            f_cmp = f.lower() if case_insensitive else f
            
            if text:  # ç›®æ ‡æ–‡ä»¶ååŒ…å«æ‰©å±•å
                if f_cmp == tname_cmp:
                    return os.path.join(root, f)
            else:  # ç›®æ ‡æ–‡ä»¶åä¸å«æ‰©å±•åï¼ŒæŒ‰ä¼˜å…ˆçº§åŒ¹é…
                fbase, fext = os.path.splitext(f)
                fbase_cmp = fbase.lower() if case_insensitive else fbase
                
                if fbase_cmp == tbase_cmp:
                    rank = prefer_exts.index(fext.lower()) if fext.lower() in prefer_exts else len(prefer_exts) + 1
                    if rank < best_rank:
                        best_rank = rank
                        best_path = os.path.join(root, f)
                        if best_rank == 0:
                            return best_path

    return best_path


def parse_arguments():
    """
    è§£æå‘½ä»¤è¡Œå‚æ•°
    
    Returns:
        argparse.Namespace: è§£æåçš„å‚æ•°å¯¹è±¡
    """
    import argparse
    
    parser = argparse.ArgumentParser(
        description='å­¦å ‚åœ¨çº¿QAå¯¹è¯èšç±»åˆ†æå·¥å…·',
        formatter_class=argparse.RawDescriptionHelpFormatter
    )
    
    # å¿…éœ€å‚æ•°
    parser.add_argument(
        '--dialog_folder',
        required=True,
        help='å¯¹è¯æ–‡ä»¶æ‰€åœ¨æ–‡ä»¶å¤¹è·¯å¾„'
    )
    parser.add_argument(
        '--class_time_file',
        required=True,
        help='è¯¾ç¨‹æ—¶é—´ä¿¡æ¯æ–‡ä»¶è·¯å¾„ï¼ˆåŒ…å«è¯¾ç¨‹å¼€å§‹å’Œç»“æŸæ—¶é—´ï¼‰'
    )
    parser.add_argument(
        '--homework_file',
        required=True,
        help='ä½œä¸šä¿¡æ¯æ–‡ä»¶è·¯å¾„'
    )
    parser.add_argument(
        '--class_schedule_file',
        required=True,
        help='è¯¾ç¨‹è¡¨æ–‡ä»¶è·¯å¾„ï¼ˆåŒ…å«å¼€è¯¾æ—¶é—´ï¼‰'
    )
    
    # å¯é€‰å‚æ•°
    parser.add_argument(
        '--school_info_file',
        required=False,
        default='',
        help='å­¦æ ¡åŸºæœ¬ä¿¡æ¯æ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰'
    )
    parser.add_argument(
        '--class_info_file',
        required=False,
        default='',
        help='ç­çº§ä¿¡æ¯æ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰'
    )
    parser.add_argument(
        '--max_k',
        type=int,
        default=DEFAULT_MAX_K,
        help=f'æœ€å¤§èšç±»æ•°ï¼ˆé»˜è®¤ï¼š{DEFAULT_MAX_K}ï¼‰'
    )
    parser.add_argument(
        '--variance_threshold',
        type=float,
        default=DEFAULT_VARIANCE_THRESHOLD,
        help=f'PCAæ–¹å·®é˜ˆå€¼ï¼ˆé»˜è®¤ï¼š{DEFAULT_VARIANCE_THRESHOLD}ï¼‰'
    )
    
    return parser.parse_args()


def validate_input_files(
    dialog_folder: str,
    class_time_file: str,
    homework_file: str,
    class_schedule_file: str
) -> List[str]:
    """
    éªŒè¯è¾“å…¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    
    Args:
        dialog_folder: å¯¹è¯æ–‡ä»¶å¤¹è·¯å¾„
        class_time_file: è¯¾ç¨‹æ—¶é—´æ–‡ä»¶è·¯å¾„
        homework_file: ä½œä¸šæ–‡ä»¶è·¯å¾„
        class_schedule_file: è¯¾ç¨‹è¡¨æ–‡ä»¶è·¯å¾„
    
    Returns:
        list: ç¼ºå¤±çš„æ–‡ä»¶åˆ—è¡¨
    """
    missing_files = []
    
    if not os.path.exists(dialog_folder):
        missing_files.append(f"Dialog folder: {dialog_folder}")
    
    for file_path, file_desc in [
        (class_time_file, "Class time file"),
        (homework_file, "Homework file"),
        (class_schedule_file, "Class schedule file")
    ]:
        if not os.path.exists(file_path):
            missing_files.append(f"{file_desc}: {file_path}")
    
    return missing_files


def organize_dialogs_by_cluster(
    features_df: pd.DataFrame,
    dialog_folder: str,
    output_folder: str,
    cluster_col: str = "cluster",
) -> None:
    """
    æ ¹æ®èšç±»ç»“æœç»„ç»‡å¯¹è¯æ–‡ä»¶ã€‚
    ä¼šè·³è¿‡ç›®æ ‡è·¯å¾„ä¸æºè·¯å¾„ç›¸åŒçš„æ–‡ä»¶ã€‚
    """
    import os
    import shutil

    if cluster_col not in features_df.columns:
        print(f"âš ï¸ '{cluster_col}' column not found â€” skipping file organization")
        return

    print(f"\nğŸ“ Organizing dialogs by '{cluster_col}'...")

    for cluster_id, group_df in features_df.groupby(cluster_col):
        cluster_folder = os.path.join(output_folder, f"cluster_{cluster_id}")
        os.makedirs(cluster_folder, exist_ok=True)
        print(f"  ğŸ“¦ Creating folder: cluster_{cluster_id} ({len(group_df)} dialogs)")

        for _, row in group_df.iterrows():
            file_name = row.get("file_name")
            if not file_name:
                continue

            src_path = find_file_recursively(
                dialog_folder,
                file_name,
                prefer_exts=PREFERRED_FILE_EXTENSIONS,
                case_insensitive=True,
            )

            if not src_path or not os.path.exists(src_path):
                print(f"âš ï¸ Source file not found: {file_name}")
                continue

            dst_path = os.path.join(cluster_folder, os.path.basename(src_path))

            # ğŸš« è·³è¿‡æºæ–‡ä»¶ä¸ç›®æ ‡æ–‡ä»¶ç›¸åŒçš„æƒ…å†µ
            try:
                if os.path.samefile(src_path, dst_path):
                    # samefile åœ¨ä¸åŒç³»ç»Ÿä¸‹å…¼å®¹åˆ¤æ–­ inode/è·¯å¾„æ˜¯å¦ä¸€è‡´
                    print(f"âš ï¸ Skipped (same file): {file_name}")
                    continue
            except FileNotFoundError:
                # os.path.samefile è¦æ±‚æ–‡ä»¶å­˜åœ¨ï¼Œä¸‡ä¸€ç›®æ ‡è¿˜æ²¡åˆ›å»ºå°±å¿½ç•¥
                pass

            try:
                shutil.copy2(src_path, dst_path)
            except Exception as e:
                print(f"âš ï¸ Failed to copy {file_name}: {e}")


def save_analysis_config(
    output_folder: str,
    dialog_folder: str,
    total_samples: int,
    features_count: int,
    optimal_clusters: int
) -> None:
    """
    ä¿å­˜åˆ†æé…ç½®ä¿¡æ¯
    
    Args:
        output_folder: è¾“å‡ºæ–‡ä»¶å¤¹è·¯å¾„
        dialog_folder: è¾“å…¥å¯¹è¯æ–‡ä»¶å¤¹è·¯å¾„
        total_samples: æ ·æœ¬æ€»æ•°
        features_count: ç‰¹å¾æ•°é‡
        optimal_clusters: æœ€ä¼˜èšç±»æ•°
    """
    config_info = {
        'dialog_folder': dialog_folder,
        'output_folder': output_folder,
        'total_samples': total_samples,
        'features_count': features_count,
        'optimal_clusters': optimal_clusters,
        'analysis_timestamp': pd.Timestamp.now().isoformat()
    }
    
    config_file = os.path.join(output_folder, 'analysis_config.json')
    with open(config_file, 'w', encoding='utf-8') as f:
        json.dump(config_info, f, indent=2, ensure_ascii=False)
    
    print(f"ğŸ“„ Configuration saved to: {config_file}")


def main() -> Tuple[Optional[pd.DataFrame], Optional[pd.DataFrame]]:
    """
    ä¸»å‡½æ•°ï¼šæ‰§è¡Œå®Œæ•´çš„èšç±»åˆ†ææµç¨‹
    
    Returns:
        tuple: (èšç±»åçš„ç‰¹å¾DataFrame, ç°‡ç‰¹å¾å‡å€¼DataFrame)
    """
    setup_plotting()
    args = parse_arguments()

    # é…ç½®è·¯å¾„
    dialog_folder = args.dialog_folder
    output_folder = os.path.join(dialog_folder, "clustering_results")
    
    # éªŒè¯è¾“å…¥æ–‡ä»¶
    if not os.path.exists(dialog_folder):
        print(f"âŒ Error: Dialog folder does not exist: {dialog_folder}")
        sys.exit(1)
    
    # æ‰“å°é…ç½®ä¿¡æ¯
    print("=" * 50)
    print("Clustering Analysis Configuration")
    print("=" * 50)
    print(f"Dialog folder:       {dialog_folder}")
    print(f"Output folder:       {output_folder}")
    print(f"Class time file:     {args.class_time_file}")
    print(f"Homework file:       {args.homework_file}")
    print(f"Class schedule file: {args.class_schedule_file}")
    print(f"Class info file:     {args.class_info_file or 'Not provided'}")
    print(f"School info file:    {args.school_info_file or 'Not provided'}")
    print(f"Max K:               {args.max_k}")
    print(f"Variance threshold:  {args.variance_threshold}")
    print("=" * 50)
    
    # æ£€æŸ¥å¿…è¦æ–‡ä»¶
    missing_files = validate_input_files(
        dialog_folder,
        args.class_time_file,
        args.homework_file,
        args.class_schedule_file
    )
    
    if missing_files:
        print("\nâš ï¸ Warning: Missing reference files:")
        for missing in missing_files:
            print(f"  - {missing}")
        print("Analysis will continue with available data...\n")
    
    # åˆ›å»ºè¾“å‡ºæ–‡ä»¶å¤¹
    os.makedirs(output_folder, exist_ok=True)
    
    print("\n" + "=" * 50)
    print("Starting Feature Extraction and Clustering Analysis")
    print("=" * 50)
    
    try:
        # æ­¥éª¤1: ç‰¹å¾æå–
        print("\n[1/7] Extracting features...")
        features_df = extract_all_features(
            dialog_folder,
            args.class_time_file,
            args.homework_file,
            args.class_schedule_file,
            school_info_file=args.school_info_file,
            class_info_file=args.class_info_file
        )
        
        if features_df.empty:
            print("âŒ Error: No features extracted, terminating program")
            return None, None
        
        print(f"âœ… Successfully extracted features from {len(features_df)} dialogs")
        
        # è°ƒè¯•å’Œä¿å­˜ç‰¹å¾
        print("\n[Debug] Checking extracted features...")
        debug_infinite_values(features_df)
        
        features_file = os.path.join(output_folder, 'extracted_features.csv')
        features_df.to_csv(features_file, index=False, encoding='utf-8-sig')
        print(f"ğŸ’¾ Features saved to: {features_file}")
        
        # æ˜¾ç¤ºæè¿°æ€§ç»Ÿè®¡
        feature_columns = [col for col in features_df.columns 
                          if col not in ['file_name', 'class_id']]
        if feature_columns and len(features_df) > 0:
            print("\nğŸ“Š Feature Descriptive Statistics:")
            print(features_df[feature_columns].describe())
        
        # æ­¥éª¤2: PCAåˆ†æ
        print("\n[2/7] Performing PCA analysis...")
        X_scaled, X_pca, pca, scaler, feature_cols = perform_pca_analysis(
            features_df, output_folder
        )
        
        # æ­¥éª¤3: å¯»æ‰¾æœ€ä¼˜èšç±»æ•°
        print("\n[3/7] Finding optimal number of clusters (elbow method)...")
        optimal_k, X_cluster = find_optimal_clusters_elbow_only(
            X_pca, pca, max_k=args.max_k, output_folder=output_folder
        )
        
        # æ­¥éª¤4: æ‰§è¡Œèšç±»
        print(f"\n[4/7] Performing clustering analysis (K={optimal_k})...")
        cluster_labels, features_df_clustered, kmeans = perform_clustering(
            X_cluster, optimal_k, features_df, output_folder
        )
        
        clustered_file = os.path.join(output_folder, 'clustered_features.csv')
        features_df_clustered.to_csv(clustered_file, index=False, encoding='utf-8-sig')
        print(f"ğŸ’¾ Clustered features saved to: {clustered_file}")
        
        # æ­¥éª¤5: åˆ†æç°‡ç‰¹å¾
        print("\n[5/7] Analyzing cluster characteristics...")
        cluster_means = analyze_cluster_characteristics(
            features_df_clustered, feature_cols, output_folder
        )
        
        # æ­¥éª¤6: ç”Ÿæˆå¯è§†åŒ–
        print("\n[6/7] Generating visualizations...")
        comprehensive_clustering_visualization_all_k(
            X_scaled, X_pca, features_df_clustered, feature_columns,
            DEFAULT_CLUSTER_COLUMNS, output_folder
        )
        
        # æ­¥éª¤7: ç»„ç»‡å¯¹è¯æ–‡ä»¶
        print("\n[7/7] Organizing dialogs by cluster...")
        organize_dialogs_by_cluster(
            features_df_clustered, dialog_folder, output_folder
        )
        
        # ä¿å­˜é…ç½®ä¿¡æ¯
        save_analysis_config(
            output_folder, dialog_folder, len(features_df_clustered),
            len(feature_cols), optimal_k
        )
        
        # è¾“å‡ºæœ€ç»ˆæ‘˜è¦
        print("\n" + "=" * 50)
        print("Analysis Complete!")
        print("=" * 50)
        print(f"ğŸ“ Results saved to:  {output_folder}")
        print(f"ğŸ“Š Total samples:     {len(features_df_clustered):,}")
        print(f"ğŸ“ˆ Features:          {len(feature_cols)}")
        print(f"ğŸ¯ Clusters:          {optimal_k}")
        print("=" * 50)
        
        return features_df_clustered, cluster_means
        
    except Exception as e:
        print(f"\nâŒ Analysis failed: {e}")
        import traceback
        traceback.print_exc()
        return None, None


if __name__ == '__main__':
    main()