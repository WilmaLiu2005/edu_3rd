"""
ç‰¹å¾å·¥å…·æ¨¡å—

æä¾›ç‰¹å¾å¤„ç†ç›¸å…³çš„å·¥å…·å‡½æ•°ï¼ŒåŒ…æ‹¬ï¼š
- æ— ç©·å¤§å€¼å¤„ç†
- å…³é”®è¯æ£€æµ‹
- æ–‡æœ¬è§„èŒƒåŒ–
"""

from typing import List, Optional
import re
import numpy as np
import pandas as pd

# å¸¸é‡å®šä¹‰
COPY_KEYWORDS = [
    "å¦‚ä¸‹", "å¦‚ä¸Š", "è¿™é“é¢˜", "æ€ä¹ˆåš", "åšæ³•",
    "A.", "B.", "C.", "D.", "æˆ‘å¯¹è¿™ä¸€é¡µä¸æ‡‚"
]

DEFAULT_REPLACEMENT_VALUE = 168.0  # é»˜è®¤æ›¿æ¢å€¼ï¼ˆä¸€å‘¨çš„å°æ—¶æ•°ï¼‰

# ç‰¹å¾åˆ—åˆ—è¡¨
FEATURE_COLUMNS = [
    'qa_turns', 'is_multi_turn', 'total_time_minutes', 'avg_qa_time_minutes',
    'total_question_chars', 'avg_question_length',
    'if_non_class', 'avg_hours_to_assignment', 'avg_hours_since_release',
    'course_progress_ratio', 'calendar_week_since_2025_0217',
    'hours_to_next_class', 'hours_from_last_class', 'has_copy_keywords', 'copy_keywords_count',
    'is_exam_week', 'day_period', 'is_weekend',
    'is_in_class_time', 'question_type_why_how'
]


def replace_inf_with_reasonable_value(
    series: pd.Series,
    multiplier: float = 1.5
) -> pd.Series:
    """
    å°†æ— ç©·å¤§å€¼æ›¿æ¢ä¸ºåˆç†çš„æœ‰é™å€¼
    
    Args:
        series: å¾…å¤„ç†çš„æ•°æ®åºåˆ—
        multiplier: ä¹˜æ•°å› å­ï¼ˆå½“å‰æœªä½¿ç”¨ï¼Œä¿ç•™ç”¨äºæœªæ¥æ‰©å±•ï¼‰
    
    Returns:
        pd.Series: æ›¿æ¢åçš„æ•°æ®åºåˆ—
    """
    if series.empty:
        return series
    
    # ä½¿ç”¨é»˜è®¤å€¼æ›¿æ¢æ— ç©·å¤§
    series_cleaned = series.replace([np.inf, -np.inf], DEFAULT_REPLACEMENT_VALUE)
    
    return series_cleaned


def debug_infinite_values(features_df: pd.DataFrame) -> None:
    """
    è°ƒè¯•å¹¶æ‰“å°æ•°æ®ä¸­çš„æ— ç©·å¤§å€¼å’ŒNaNå€¼ä¿¡æ¯
    
    Args:
        features_df: ç‰¹å¾DataFrame
    """
    print("\n" + "=" * 50)
    print("Checking Infinite Values")
    print("=" * 50)
    
    print("\nAvailable columns in features_df:")
    print(features_df.columns.tolist())
    
    has_issues = False
    
    for col in FEATURE_COLUMNS:
        if col not in features_df.columns:
            continue
        
        inf_count = np.isinf(features_df[col]).sum()
        nan_count = np.isnan(features_df[col]).sum()
        
        if inf_count > 0 or nan_count > 0:
            has_issues = True
            print(f"\nâš ï¸ Column '{col}':")
            print(f"   - Infinite values: {inf_count}")
            print(f"   - NaN values: {nan_count}")
            
            if inf_count > 0:
                inf_indices = features_df[np.isinf(features_df[col])].index
                print(f"   - Infinite values in rows: {inf_indices.tolist()[:5]}...")
                
                if 'file_name' in features_df.columns:
                    sample_files = features_df.loc[inf_indices[:3], 'file_name'].tolist()
                    print(f"   - Sample files: {sample_files}")
        
        # æ˜¾ç¤ºåŸºæœ¬ç»Ÿè®¡ï¼ˆæ’é™¤æ— ç©·å¤§å€¼ï¼‰
        finite_data = features_df[col][np.isfinite(features_df[col])]
        if not finite_data.empty:
            print(f"\nğŸ“Š {col} (finite values only):")
            print(f"   - Min:  {finite_data.min():.2f}")
            print(f"   - Max:  {finite_data.max():.2f}")
            print(f"   - Mean: {finite_data.mean():.2f}")
            print(f"   - Std:  {finite_data.std():.2f}")
        else:
            print(f"\nâŒ {col}: All values are infinite or NaN")
    
    if not has_issues:
        print("\nâœ… No infinite or NaN values found in feature columns")
    
    print("=" * 50)


def normalize_for_keyword(text: str) -> str:
    """
    è§„èŒƒåŒ–æ–‡æœ¬ç”¨äºå…³é”®è¯æ£€æµ‹
    
    å¤„ç†æ­¥éª¤ï¼š
    1. å»é™¤Markdowné“¾æ¥ï¼Œä¿ç•™å¯è§æ–‡æœ¬
    2. å…¨è§’å­—ç¬¦è½¬åŠè§’
    3. å»é™¤æ‰€æœ‰ç©ºç™½å­—ç¬¦
    
    Args:
        text: å¾…è§„èŒƒåŒ–çš„æ–‡æœ¬
    
    Returns:
        str: è§„èŒƒåŒ–åçš„æ–‡æœ¬
    """
    if text is None:
        return ""
    
    s = str(text)
    
    # å»é™¤Markdowné“¾æ¥ï¼Œåªä¿ç•™å¯è§æ–‡æœ¬
    s = re.sub(r'\[([^\]]+)\]\([^)]+\)', r'\1', s)
    
    # å…¨è§’è½¬åŠè§’
    result = []
    for ch in s:
        code = ord(ch)
        if code == 0x3000:  # å…¨è§’ç©ºæ ¼
            code = 32
        elif 0xFF01 <= code <= 0xFF5E:  # å…¶ä»–å…¨è§’å­—ç¬¦
            code -= 0xFEE0
        result.append(chr(code))
    s = "".join(result)
    
    # å»é™¤æ‰€æœ‰ç©ºç™½å­—ç¬¦ï¼ˆé¿å…"è¿™ é“ é¢˜"è¢«æ¼æ£€ï¼‰
    s = re.sub(r'\s+', '', s)
    
    return s


def contains_copy_keywords(
    text: str,
    keywords: List[str] = COPY_KEYWORDS
) -> bool:
    """
    æ£€æµ‹æ–‡æœ¬ä¸­æ˜¯å¦åŒ…å«å¤åˆ¶ç²˜è´´ç›¸å…³çš„å…³é”®è¯
    
    Args:
        text: å¾…æ£€æµ‹çš„æ–‡æœ¬
        keywords: å…³é”®è¯åˆ—è¡¨
    
    Returns:
        bool: æ˜¯å¦åŒ…å«å…³é”®è¯
    """
    normalized_text = normalize_for_keyword(text)
    
    if not normalized_text:
        return False
    
    return any(keyword in normalized_text for keyword in keywords)


def count_copy_keywords(
    text: str,
    keywords: List[str] = COPY_KEYWORDS
) -> int:
    """
    ç»Ÿè®¡æ–‡æœ¬ä¸­åŒ…å«çš„å…³é”®è¯æ•°é‡
    
    Args:
        text: å¾…æ£€æµ‹çš„æ–‡æœ¬
        keywords: å…³é”®è¯åˆ—è¡¨
    
    Returns:
        int: å…³é”®è¯å‡ºç°æ¬¡æ•°
    """
    normalized_text = normalize_for_keyword(text)
    
    if not normalized_text:
        return 0
    
    count = sum(1 for keyword in keywords if keyword in normalized_text)
    return count