import os
import glob
import json
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from .io_utils import load_reference_data
from .time_utils import (
    get_teaching_week,
    get_time_to_next_class,
    get_time_from_last_class,
)
from .homework_utils import (
    get_hours_to_next_assignment,
    get_hours_since_last_assignment_release,
)
from .feature_utils import replace_inf_with_reasonable_value, contains_copy_keywords, COPY_KEYWORDS
from .config import ANCHOR_DATE


def extract_features_from_dialog(
    file_path,
    df_class,
    df_homework,
    df_schedule,
    df_school=None,
    stats=None,
    before_course_value=-0.1,
    after_course_value=1.1,
):
    """
    ä»å•ä¸ªå¯¹è¯æ–‡ä»¶ä¸­æå–ç‰¹å¾ï¼ˆå¢å¼ºç‰ˆï¼‰

    - ä¿ç•™åŸæ‰€æœ‰ç‰¹å¾é€»è¾‘
    - æ–°å¢: æ˜¯å¦è€ƒè¯•å‘¨ã€ä¸€å¤©æ—¶æ®µã€æ˜¯å¦å‘¨æœ«ã€æ˜¯å¦ä¸Šè¯¾æ—¶é—´å†…ã€æ˜¯å¦â€œä¸ºä»€ä¹ˆ/æ€ä¹ˆ/ä¸ºå•¥â€æé—®
    """
    try:
        # === åˆå§‹åŒ–ç»Ÿè®¡ ===
        if stats is not None:
            stats["total"] = stats.get("total", 0) + 1

        if not os.path.exists(file_path):
            print(f"âŒ File not found: {file_path}")
            if stats is not None:
                stats["File not found"] = stats.get("File not found", 0) + 1
            return None

        # === åŠ è½½æ•°æ® ===
        df = pd.read_csv(file_path, encoding="utf-8-sig")
        if df.empty:
            print(f"âš ï¸ Empty file: {os.path.basename(file_path)}")
            stats and stats.update({"File is empty": stats.get("File is empty", 0) + 1})
            return None

        required_cols = ["æé—®æ—¶é—´", "æé—®å†…å®¹", "AIå›å¤"]
        missing_cols = [col for col in required_cols if col not in df.columns]
        if missing_cols:
            print(f"âš ï¸ Missing columns {missing_cols} in {os.path.basename(file_path)}")
            stats and stats.update({"missing columns": stats.get("missing columns", 0) + 1})
            return None

        df.fillna("", inplace=True)
        file_name = os.path.basename(file_path)

        # === æ ¡éªŒç­çº§ID ===
        if "æ•™å­¦ç­ID" not in df.columns:
            print(f"âš ï¸ Missing class ID column: {file_name}")
            stats and stats.update({"failed": stats.get("failed", 0) + 1})
            return None

        class_id = df["æ•™å­¦ç­ID"].iloc[0]

        # === æ—¶é—´è½¬æ¢ ===
        try:
            df["æé—®æ—¶é—´"] = pd.to_datetime(df["æé—®æ—¶é—´"], errors="coerce")
        except Exception as e:
            print(f"â° Time conversion failed in {file_name}: {e}")
            stats and stats.update({"Time conversion": stats.get("Time conversion", 0) + 1})
            return None

        if df["æé—®æ—¶é—´"].isna().any():
            print(f"âš ï¸ Invalid QA times in {file_name}")
            stats and stats.update({"Invalid QA times": stats.get("Invalid QA times", 0) + 1})
            return None

        # === ç­çº§è¿‡æ»¤ ===
        if df_school and isinstance(df_school, dict) and "df_class_info" in df_school:
            valid_ids = set(df_school["df_class_info"]["æ•™å­¦ç­ID"].astype(str))
            if str(class_id) not in valid_ids:
                print(f"â­ï¸ Skip class {class_id} (not in class_info_file): {file_name}")
                stats and stats.update({"filtered_by_class_info": stats.get("filtered_by_class_info", 0) + 1})
                return None

        # === è¯¾ç¨‹ä¿¡æ¯ ===
        class_info = df_class[df_class["æ•™å­¦ç­ID"] == class_id]
        if class_info.empty:
            print(f"âš ï¸ No class info for {class_id}: {file_name}")
            stats and stats.update({"No class info": stats.get("No class info", 0) + 1})
            return None

        course_start = pd.to_datetime(class_info["èµ·å§‹æ—¶é—´"].iloc[0], errors="coerce")
        course_end = pd.to_datetime(class_info["ç»“æŸæ—¶é—´"].iloc[0], errors="coerce")

        if pd.isna(course_start) or pd.isna(course_end):
            print(f"âš ï¸ Invalid course time for {class_id}: {file_name}")
            stats and stats.update({"Invalid course start/end time": stats.get("Invalid course start/end time", 0) + 1})
            return None

        # === è¶…å‡ºæ•™å­¦æ—¶é—´èŒƒå›´ ===
        qa_min, qa_max = df["æé—®æ—¶é—´"].min(), df["æé—®æ—¶é—´"].max()
        if qa_min < course_start or qa_max > course_end:
            print(f"ğŸš« Out of course window [{course_start}, {course_end}] -> skip: {file_name}")
            stats and stats.update({"out_of_range": stats.get("out_of_range", 0) + 1})
            return None

        # === æ£€æµ‹å¤åˆ¶é¢˜ç›® ===
        copy_keywords_count = sum(q.count(kw) for q in df["æé—®å†…å®¹"] if isinstance(q, str) for kw in COPY_KEYWORDS)
        has_copy_keywords = int(copy_keywords_count > 0)

        # === å¯¹è¯ç»Ÿè®¡ ===
        qa_turns = len(df)
        total_time = (
            (df["æé—®æ—¶é—´"].max() - df["æé—®æ—¶é—´"].min()).total_seconds() / 60 if qa_turns > 1 else 0
        )
        avg_qa_time = total_time / (qa_turns - 1) if qa_turns > 1 else 0
        question_lengths = df["æé—®å†…å®¹"].astype(str).str.len()
        avg_question_length = question_lengths.mean() if not question_lengths.empty else 0.0

        if_non_class = int(df.get("æé—®å…¥å£", pd.Series(["ç­çº§"])).ne("ç­çº§").any())

        # === ä½œä¸šä¸æ—¶é—´å…³ç³» ===
        avg_hours_to_assignment = np.mean(
            [get_hours_to_next_assignment(t, class_id, df_homework) for t in df["æé—®æ—¶é—´"]]
        )
        avg_hours_since_release = np.mean(
            [get_hours_since_last_assignment_release(t, class_id, df_homework) for t in df["æé—®æ—¶é—´"]]
        )

        total_weeks = max(1, ((course_end - course_start).days // 7) + 1)
        qa_start_time = df["æé—®æ—¶é—´"].min()
        progress_values = [
            get_teaching_week(t, class_id, df_class) / total_weeks
            for t in df["æé—®æ—¶é—´"]
            if course_start <= t <= course_end
        ]

        if qa_start_time < course_start:
            course_progress_ratio = before_course_value
        elif qa_start_time > course_end:
            course_progress_ratio = after_course_value
        else:
            course_progress_ratio = float(np.mean(progress_values)) if progress_values else 0.0

        anchor = pd.Timestamp("2025-02-17")
        calendar_week = int(((qa_start_time.normalize() - anchor.normalize()).days // 7) + 1)

        avg_hours_to_next_class = np.mean(
            [get_time_to_next_class(t, class_id, df_schedule) for t in df["æé—®æ—¶é—´"]]
        )
        avg_hours_from_last_class = np.mean(
            [get_time_from_last_class(t, class_id, df_schedule) for t in df["æé—®æ—¶é—´"]]
        )

        # === æ–°å¢ç‰¹å¾ ===
        day_period = qa_start_time.hour + qa_start_time.minute / 60
        is_weekend = int(qa_start_time.weekday() >= 5)
        current_week = get_teaching_week(qa_start_time, class_id, df_class)
        is_exam_week = int(current_week >= total_weeks - 1)

        def in_class_time(t):
            schedule = df_schedule[df_schedule["æ•™å­¦ç­ID"] == class_id]
            return any(
                pd.to_datetime(row["å¼€è¯¾æ—¶é—´"], errors="coerce") <= t <= pd.to_datetime(row["ç»“è¯¾æ—¶é—´"], errors="coerce")
                for _, row in schedule.iterrows()
            )

        is_in_class_time = int(any(in_class_time(t) for t in df["æé—®æ—¶é—´"] if pd.notna(t)))
        question_texts = " ".join(df["æé—®å†…å®¹"].astype(str))
        question_type_why_how = int(any(kw in question_texts for kw in ["ä¸ºä»€ä¹ˆ", "ä¸ºå•¥", "æ€ä¹ˆ"]))

        # === æ±‡æ€»ç‰¹å¾ ===
        features = dict(
            file_name=file_name,
            class_id=class_id,
            qa_turns=int(qa_turns),
            is_multi_turn=qa_turns > 1,
            total_time_minutes=float(total_time),
            avg_qa_time_minutes=float(avg_qa_time),
            total_question_chars=int(question_lengths.sum()),
            avg_question_length=float(avg_question_length),
            if_non_class=if_non_class,
            avg_hours_to_assignment=float(avg_hours_to_assignment),
            avg_hours_since_release=float(avg_hours_since_release),
            course_progress_ratio=float(course_progress_ratio),
            calendar_week_since_2025_0217=calendar_week,
            hours_to_next_class=float(avg_hours_to_next_class),
            hours_from_last_class=float(avg_hours_from_last_class),
            has_copy_keywords=has_copy_keywords,
            copy_keywords_count=int(copy_keywords_count),
            is_exam_week=is_exam_week,
            day_period=day_period,
            is_weekend=is_weekend,
            is_in_class_time=is_in_class_time,
            question_type_why_how=question_type_why_how,
        )

        # === æ¸…ç†æ— æ•ˆå€¼ ===
        for k, v in features.items():
            if k not in ["file_name", "class_id"] and not np.isfinite(v):
                features[k] = 0.0

        stats and stats.update({"processed": stats.get("processed", 0) + 1})
        return features

    except Exception as e:
        print(f"â— Error in {file_path}: {e}")
        import traceback

        traceback.print_exc()
        return None

def plot_feature_histograms(
    df,
    features=None,
    bins=50,
    save_dir=None,
    figsize=(7, 4),
    stats_file="feature_stats.csv",
):
    """
    ç»˜åˆ¶ç‰¹å¾åˆ†å¸ƒå›¾ï¼Œå¹¶ä¿å­˜æ¯ä¸ªç‰¹å¾çš„ min/max/mean/varã€‚
    - æ•°å€¼è¿ç»­å˜é‡ç»˜åˆ¶ç›´æ–¹å›¾ï¼›
    - äºŒå…ƒå˜é‡ï¼ˆ0/1ï¼‰ç»˜åˆ¶æŸ±çŠ¶å›¾ï¼›
    - è‡ªåŠ¨è¯†åˆ«ç‰¹å¾åˆ—ã€‚
    è¿”å›ï¼šä¿å­˜çš„å›¾ç‰‡è·¯å¾„åˆ—è¡¨å’Œç»Ÿè®¡ DataFrame
    """
    save_dir = os.path.abspath(save_dir or "histograms")
    os.makedirs(save_dir, exist_ok=True)

    # === è‡ªåŠ¨è¯†åˆ«ç‰¹å¾åˆ— ===
    if features is None:
        features = df.select_dtypes(include=[np.number]).columns.tolist()
        print(f"ğŸ§­ æ£€æµ‹åˆ° {len(features)} ä¸ªæ•°å€¼å‹ç‰¹å¾ï¼š{features}")

    saved_files, stats_list = [], []

    for feature in features:
        if feature not in df.columns:
            print(f"âš ï¸ ç¼ºå¤±åˆ—ï¼š{feature} -> è·³è¿‡")
            continue

        series = pd.to_numeric(df[feature], errors="coerce").dropna()
        if series.empty:
            print(f"âš ï¸ {feature} æ— æœ‰æ•ˆæ•°æ® -> è·³è¿‡")
            continue

        # === ç»Ÿè®¡ç‰¹å¾ ===
        stats = {
            "feature": feature,
            "min": series.min(),
            "max": series.max(),
            "mean": series.mean(),
            "median": series.median(),
            "variance": series.var(),
        }
        stats_list.append(stats)

        # === ç»˜å›¾ ===
        plt.figure(figsize=figsize)
        unique_vals = sorted(series.unique())
        if len(unique_vals) <= 2 and set(unique_vals).issubset({0, 1}):
            # äºŒå…ƒå˜é‡
            counts = series.value_counts().sort_index()
            plt.bar(counts.index.astype(str), counts.values, color="skyblue", edgecolor="black")
            plt.title(f"{feature} (binary: {unique_vals})")
            plt.xlabel(feature)
            plt.ylabel("Count")
        else:
            # è¿ç»­å˜é‡
            plt.hist(series, bins=bins, color="steelblue", edgecolor="black", alpha=0.75)
            plt.axvline(series.mean(), color="red", linestyle="--", label=f"Mean={series.mean():.2f}")
            plt.axvline(series.median(), color="green", linestyle=":", label=f"Median={series.median():.2f}")
            plt.legend()
            plt.title(f"{feature} (n={len(series)})")
            plt.xlabel(feature)
            plt.ylabel("Count")

        out_path = os.path.join(save_dir, f"{feature}_dist.png")
        plt.tight_layout()
        plt.savefig(out_path)
        plt.close()
        saved_files.append(out_path)
        print(f"âœ… å·²ä¿å­˜ç›´æ–¹å›¾: {out_path}")

    # === ä¿å­˜ç»Ÿè®¡æ•°æ® ===
    stats_df = pd.DataFrame(stats_list)
    stats_path = os.path.join(save_dir, stats_file)
    stats_df.to_csv(stats_path, index=False)
    print(f"\nğŸ“Š å·²ç”Ÿæˆ {len(saved_files)} å¼ å›¾è¡¨ï¼Œç»Ÿè®¡ä¿¡æ¯ä¿å­˜åœ¨: {stats_path}")

    return saved_files, stats_df


# ======================================================================

def extract_all_features(
    dialog_folder,
    class_time_file,
    homework_file,
    class_schedule_file,
    school_info_file=None,
    class_info_file=None,
    plot_histograms=True,
):
    """
    æ‰¹é‡æå–æ‰€æœ‰å¯¹è¯æ–‡ä»¶çš„ç‰¹å¾ï¼Œå¹¶å¯é€‰ç»˜åˆ¶ç›´æ–¹å›¾ã€‚
    """
    print("ğŸ“¦ Loading reference data...")
    try:
        df_class, df_homework, df_schedule, df_school = load_reference_data(
            class_time_file,
            homework_file,
            class_schedule_file,
            school_info_file=school_info_file,
            class_info_file=class_info_file,
        )
    except Exception as e:
        print(f"âŒ Failed to load reference data: {e}")
        df_class, df_homework, df_schedule, df_school = (
            pd.DataFrame(),
            pd.DataFrame(),
            pd.DataFrame(),
            pd.DataFrame(),
        )

    print(f"ğŸ” Searching CSVs in: {dialog_folder}")

    # === é€’å½’æŸ¥æ‰¾æ‰€æœ‰ CSV æ–‡ä»¶ ===
    patterns = [
        os.path.join(dialog_folder, "*.csv"),
        os.path.join(dialog_folder, "*", "*.csv"),
        os.path.join(dialog_folder, "*", "*", "*.csv"),
        os.path.join(dialog_folder, "**", "*.csv"),
    ]
    csv_files = list({fp for p in patterns for fp in glob.glob(p, recursive=True)})

    exclude_keywords = ["feature", "cluster", "result", "statistic", "analysis", "pca"]
    dialog_files = [
        f for f in csv_files if not any(kw in os.path.basename(f).lower() for kw in exclude_keywords)
    ]
    print(f"ğŸ—‚ï¸ æ‰¾åˆ° {len(dialog_files)} ä¸ªå¯èƒ½çš„å¯¹è¯ CSV æ–‡ä»¶")

    if not dialog_files:
        print("âš ï¸ æœªæ‰¾åˆ°ä»»ä½•å¯¹è¯æ–‡ä»¶ï¼Œæ–‡ä»¶å¤¹ç»“æ„å¦‚ä¸‹ï¼š")
        for root, _, files in os.walk(dialog_folder):
            level = root.replace(dialog_folder, "").count(os.sep)
            indent = " " * 2 * level
            print(f"{indent}{os.path.basename(root)}/")
            csv_in_dir = [f for f in files if f.endswith(".csv")]
            for f in csv_in_dir[:5]:
                print(f"{indent}  {f}")
            if len(csv_in_dir) > 5:
                print(f"{indent}  ... è¿˜æœ‰ {len(csv_in_dir) - 5} ä¸ª CSV æ–‡ä»¶")
        return pd.DataFrame()

    # === æ ¡éªŒå‰10ä¸ªæ–‡ä»¶ç»“æ„ ===
    print("ğŸ§© Validating file formats...")
    valid_files = []
    required_cols = ["æé—®æ—¶é—´", "æé—®å†…å®¹", "AIå›å¤"]

    for file_path in dialog_files[:10]:
        try:
            df_test = pd.read_csv(file_path, encoding="utf-8-sig", nrows=3)
            if all(col in df_test.columns for col in required_cols):
                print(f"âœ“ {os.path.basename(file_path)} æ ¼å¼æœ‰æ•ˆ")
                valid_files.append(file_path)
            else:
                print(f"âœ— {os.path.basename(file_path)} ç¼ºå°‘å¿…è¦åˆ— -> {df_test.columns.tolist()}")
        except Exception as e:
            print(f"âœ— {os.path.basename(file_path)} è¯»å–å¤±è´¥: {e}")

    if len(valid_files) == min(10, len(dialog_files)):
        valid_files = dialog_files
        print(f"âœ… å‰10ä¸ªæ–‡ä»¶éªŒè¯é€šè¿‡ï¼Œå‡è®¾å…¨éƒ¨ {len(dialog_files)} ä¸ªæ–‡ä»¶æœ‰æ•ˆ")
    else:
        print("ğŸ” é€ä¸ªéªŒè¯å…¨éƒ¨æ–‡ä»¶...")
        valid_files = []
        for file_path in dialog_files:
            try:
                df_test = pd.read_csv(file_path, encoding="utf-8-sig", nrows=3)
                if all(col in df_test.columns for col in required_cols):
                    valid_files.append(file_path)
            except Exception:
                continue

    print(f"ğŸ“ æœ€ç»ˆæœ‰æ•ˆå¯¹è¯æ–‡ä»¶æ•°: {len(valid_files)}")
    if not valid_files:
        print("âŒ æ²¡æœ‰æœ‰æ•ˆçš„ CSV æ–‡ä»¶ï¼")
        return pd.DataFrame()

    # === æå–ç‰¹å¾ ===
    features_list = []
    stats = {"total": 0, "processed": 0, "failed": 0, "out_of_range": 0}
    failed_count = 0

    for i, file_path in enumerate(valid_files, start=1):
        if i % 100 == 0:
            print(f"â³ Progress: {i}/{len(valid_files)}")

        features = extract_features_from_dialog(
            file_path,
            df_class,
            df_homework,
            df_schedule,
            df_school=df_school,
            stats=stats,
        )
        if features is not None:
            features_list.append(features)
        else:
            failed_count += 1
            if failed_count <= 5:
                print(f"âš ï¸ ç‰¹å¾æå–å¤±è´¥: {os.path.basename(file_path)}")

    print(f"âœ… æˆåŠŸæå– {len(features_list)} ä¸ªæ–‡ä»¶ç‰¹å¾ï¼Œå¤±è´¥ {failed_count} ä¸ª")

    # === ä¿å­˜ç»Ÿè®¡ ===
    stats_to_save = {
        "valid_files_found": len(valid_files),
        "total_dialog_calls": stats.get("total", 0),
        "processed_dialogs": stats.get("processed", 0),
        "out_of_range_dialogs": stats.get("out_of_range", 0),
        "successful_feature_rows": len(features_list),
        "stats": stats,
    }
    total = stats_to_save["total_dialog_calls"]
    if total > 0:
        stats_to_save.update(
            {
                "success_ratio": stats["processed"] / total,
                "out_of_range_ratio": stats["out_of_range"] / total,
                "fail_ratio": (stats["out_of_range"] + stats["failed"]) / total,
            }
        )

    stats_dir = os.path.dirname(os.path.abspath(homework_file))
    os.makedirs(stats_dir, exist_ok=True)
    stats_path = os.path.join(stats_dir, "dialog_stats.json")
    with open(stats_path, "w", encoding="utf-8") as f:
        json.dump(stats_to_save, f, ensure_ascii=False, indent=2)
    print(f"ğŸ“Š ç»Ÿè®¡ä¿¡æ¯ä¿å­˜åˆ°: {stats_path}")

    if not features_list:
        print("âš ï¸ æ²¡æœ‰æˆåŠŸçš„ç‰¹å¾ç»“æœï¼")
        return pd.DataFrame()

    # === æ„å»º DataFrame ===
    features_df = pd.DataFrame(features_list)

    # === æ›¿æ¢æ— ç©·å¤§å€¼ ===
    print("â™»ï¸ å¤„ç† class æ—¶é—´ç‰¹å¾ä¸­çš„æ— ç©·å¤§å€¼...")
    for col in ["hours_to_next_class", "hours_from_last_class"]:
        if col in features_df.columns and np.isinf(features_df[col]).any():
            features_df[col] = replace_inf_with_reasonable_value(features_df[col], multiplier=1.5)

    # === ç»˜åˆ¶ç›´æ–¹å›¾ ===
    if plot_histograms:
        hist_dir = os.path.join(stats_dir, "histograms_before_log")
        print(f"ğŸ–¼ï¸ ç»˜åˆ¶åŸå§‹ç‰¹å¾åˆ†å¸ƒå›¾åˆ°: {hist_dir}")
        plot_feature_histograms(features_df, save_dir=hist_dir)

    # === log(1+x) å˜æ¢ ===
    log_features = [
        "avg_hours_since_release",
        "avg_hours_to_assignment",
        "avg_qa_time_minutes",
        "avg_question_length",
        "copy_keywords_count",
        "course_progress_ratio",
        "qa_turns",
        "total_question_chars",
        "total_time_minutes",
        "hours_from_last_class",
        "hours_to_next_class",
    ]
    for col in log_features:
        if col in features_df.columns:
            features_df[col] = np.log1p(features_df[col])

    if plot_histograms:
        hist_dir = os.path.join(stats_dir, "histograms_after_log")
        print(f"ğŸ–¼ï¸ ç»˜åˆ¶ log ç‰¹å¾åˆ†å¸ƒå›¾åˆ°: {hist_dir}")
        plot_feature_histograms(features_df, save_dir=hist_dir)

    return features_df
